{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**<a id=\"1\"></a>\n# <p style=\"background-image: url(https://i.postimg.cc/K87ByXmr/stage5.jpg);font-family:camtasia;font-size:120%;color:white;text-align:center;border-radius:15px 50px; padding:7px\"> Welcome to my notebook</p>","metadata":{}},{"cell_type":"markdown","source":"# 1. Introduction","metadata":{}},{"cell_type":"markdown","source":" Leaf disease detection is a critical aspect of modern agriculture and plant science. It involves the identification and diagnosis of diseases that affect the leaves of plants. These diseases can significantly impact crop yield, quality, and overall plant health, making their early detection and management essential for sustainable agriculture. ","metadata":{}},{"cell_type":"markdown","source":"#  Importance of Leaf Disease Detection:\n\n**Crop Health and Yield:** Healthy leaves are vital for photosynthesis, which is the process that enables plants to produce energy and grow. Leaf diseases can reduce photosynthesis, leading to decreased crop yield and quality.\n\n**Early Detection:** Identifying leaf diseases in their early stages is crucial for effective management. Early detection allows farmers and researchers to implement timely interventions, such as applying fungicides or adjusting irrigation, to prevent disease spread and minimize damage.\n\n**Crop Protection:** Leaf diseases can spread rapidly in agricultural fields, leading to significant economic losses. Detecting and controlling these diseases help protect crops and ensure food security.","metadata":{}},{"cell_type":"markdown","source":"# **Import requirment libraries and tools**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Activation\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:35.963469Z","iopub.execute_input":"2023-10-30T05:39:35.963742Z","iopub.status.idle":"2023-10-30T05:39:44.343016Z","shell.execute_reply.started":"2023-10-30T05:39:35.963718Z","shell.execute_reply":"2023-10-30T05:39:44.341985Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# import directory and path","metadata":{}},{"cell_type":"code","source":"directory='/kaggle/input/leaf-data'\ncategories=['Strawberry_fresh','Strawberry_scrotch']","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:44.344636Z","iopub.execute_input":"2023-10-30T05:39:44.345117Z","iopub.status.idle":"2023-10-30T05:39:44.351933Z","shell.execute_reply.started":"2023-10-30T05:39:44.345092Z","shell.execute_reply":"2023-10-30T05:39:44.348864Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# path connection","metadata":{}},{"cell_type":"code","source":"data=[]\nfor categori in categories:\n    folder=os.path.join(directory,categori)\n    print(folder)\n    label=categories.index(categori)# we defined label in categories\n    \n    for img in os.listdir(folder):\n        img=os.path.join(folder,img)#connection between folder and image\n        \n        #print(img)\n        img_arr=cv2.imread(img)#convert image to array\n        #plt.imshow(img_arr)\n        #break #f we want image show\n        \n        img_arr=cv2.resize(img_arr,(100,100))\n        \n        data.append([img_arr,label])","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:44.353412Z","iopub.execute_input":"2023-10-30T05:39:44.353762Z","iopub.status.idle":"2023-10-30T05:39:44.970959Z","shell.execute_reply.started":"2023-10-30T05:39:44.353726Z","shell.execute_reply":"2023-10-30T05:39:44.970180Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/leaf-data/Strawberry_fresh\n/kaggle/input/leaf-data/Strawberry_scrotch\n","output_type":"stream"}]},{"cell_type":"code","source":"#data #show image array and label","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:44.973393Z","iopub.execute_input":"2023-10-30T05:39:44.973696Z","iopub.status.idle":"2023-10-30T05:39:44.977838Z","shell.execute_reply.started":"2023-10-30T05:39:44.973671Z","shell.execute_reply":"2023-10-30T05:39:44.976812Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"random.shuffle(data)#convert sequence data to random data \n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:44.978910Z","iopub.execute_input":"2023-10-30T05:39:44.979164Z","iopub.status.idle":"2023-10-30T05:39:44.988978Z","shell.execute_reply.started":"2023-10-30T05:39:44.979141Z","shell.execute_reply":"2023-10-30T05:39:44.988176Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x=[]#image array \ny=[]#label array\nfor features,label in data:\n    x.append(features)\n    y.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:44.989853Z","iopub.execute_input":"2023-10-30T05:39:44.990112Z","iopub.status.idle":"2023-10-30T05:39:45.001157Z","shell.execute_reply.started":"2023-10-30T05:39:44.990091Z","shell.execute_reply":"2023-10-30T05:39:45.000065Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X=np.array(x)#convert feature list to array\nY=np.array(y)#convert label list to array","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:45.002173Z","iopub.execute_input":"2023-10-30T05:39:45.002459Z","iopub.status.idle":"2023-10-30T05:39:45.014219Z","shell.execute_reply.started":"2023-10-30T05:39:45.002436Z","shell.execute_reply":"2023-10-30T05:39:45.013527Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Normalize ","metadata":{}},{"cell_type":"code","source":"X=X/255#rescalling","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:45.015365Z","iopub.execute_input":"2023-10-30T05:39:45.015682Z","iopub.status.idle":"2023-10-30T05:39:45.031436Z","shell.execute_reply.started":"2023-10-30T05:39:45.015648Z","shell.execute_reply":"2023-10-30T05:39:45.030431Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X.shape#1st 100 means 100 image then 100*100 image size and then 3 means rgb","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:45.032721Z","iopub.execute_input":"2023-10-30T05:39:45.033007Z","iopub.status.idle":"2023-10-30T05:39:45.041418Z","shell.execute_reply.started":"2023-10-30T05:39:45.032981Z","shell.execute_reply":"2023-10-30T05:39:45.040452Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(100, 100, 100, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"# proceesing complete","metadata":{}},{"cell_type":"code","source":"model=Sequential()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:45.044101Z","iopub.execute_input":"2023-10-30T05:39:45.044371Z","iopub.status.idle":"2023-10-30T05:39:48.089429Z","shell.execute_reply.started":"2023-10-30T05:39:45.044349Z","shell.execute_reply":"2023-10-30T05:39:48.088386Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"filter size 32 and kernel size 3*3,input shape 100*100","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(32,(3,3),input_shape=X.shape[1:],activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())#connect final layer\nmodel.add(Dense(2,activation='softmax'))#final output 2\n          ","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:48.090686Z","iopub.execute_input":"2023-10-30T05:39:48.091069Z","iopub.status.idle":"2023-10-30T05:39:48.178364Z","shell.execute_reply.started":"2023-10-30T05:39:48.091031Z","shell.execute_reply":"2023-10-30T05:39:48.177638Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# compile and detect loss","metadata":{}},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:48.179389Z","iopub.execute_input":"2023-10-30T05:39:48.179685Z","iopub.status.idle":"2023-10-30T05:39:48.194411Z","shell.execute_reply.started":"2023-10-30T05:39:48.179660Z","shell.execute_reply":"2023-10-30T05:39:48.193435Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#X is independent variable and Y is dependent variable and 10% data test and 90% train","metadata":{}},{"cell_type":"code","source":"model.fit(X,Y,epochs=15,validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:48.195639Z","iopub.execute_input":"2023-10-30T05:39:48.196245Z","iopub.status.idle":"2023-10-30T05:39:56.720213Z","shell.execute_reply.started":"2023-10-30T05:39:48.196198Z","shell.execute_reply":"2023-10-30T05:39:56.719339Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/15\n3/3 [==============================] - 8s 142ms/step - loss: 1.8354 - accuracy: 0.5333 - val_loss: 1.2218 - val_accuracy: 0.6000\nEpoch 2/15\n3/3 [==============================] - 0s 18ms/step - loss: 1.4071 - accuracy: 0.5000 - val_loss: 0.5002 - val_accuracy: 0.8000\nEpoch 3/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.6708 - accuracy: 0.6222 - val_loss: 0.9749 - val_accuracy: 0.4000\nEpoch 4/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.4670 - accuracy: 0.7111 - val_loss: 0.4290 - val_accuracy: 0.8000\nEpoch 5/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.3421 - accuracy: 0.8222 - val_loss: 0.7101 - val_accuracy: 0.6000\nEpoch 6/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.3509 - accuracy: 0.8222 - val_loss: 0.3761 - val_accuracy: 0.9000\nEpoch 7/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.2015 - accuracy: 0.9444 - val_loss: 0.3566 - val_accuracy: 0.8000\nEpoch 8/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.1793 - accuracy: 0.9778 - val_loss: 0.2607 - val_accuracy: 0.9000\nEpoch 9/15\n3/3 [==============================] - 0s 18ms/step - loss: 0.1155 - accuracy: 0.9778 - val_loss: 0.2381 - val_accuracy: 0.9000\nEpoch 10/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.0933 - accuracy: 0.9889 - val_loss: 0.2140 - val_accuracy: 0.9000\nEpoch 11/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9000\nEpoch 12/15\n3/3 [==============================] - 0s 18ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 1.0000\nEpoch 13/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 1.0000\nEpoch 14/15\n3/3 [==============================] - 0s 18ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 1.0000\nEpoch 15/15\n3/3 [==============================] - 0s 17ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 1.0000\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f76e0554f40>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:56.721292Z","iopub.execute_input":"2023-10-30T05:39:56.721609Z","iopub.status.idle":"2023-10-30T05:39:56.741819Z","shell.execute_reply.started":"2023-10-30T05:39:56.721582Z","shell.execute_reply":"2023-10-30T05:39:56.740895Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 98, 98, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n )                                                               \n                                                                 \n flatten (Flatten)           (None, 76832)             0         \n                                                                 \n dense (Dense)               (None, 2)                 153666    \n                                                                 \n=================================================================\nTotal params: 154,562\nTrainable params: 154,562\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# model prediction","metadata":{}},{"cell_type":"code","source":"#from keras.preprocessing import image\nimport keras.utils as image\nfrom keras.utils import load_img, img_to_array\nimport numpy as np\nimg_pred=image.load_img('/kaggle/input/leaf-data/Strawberry_scrotch/01f11949-54ba-4c0e-afb7-1e435ecac63a___RS_L.Scorch 0045.JPG',target_size=(100,100))\nimg_pred=image.img_to_array(img_pred)\nimg_pred=np.expand_dims(img_pred,axis=0)#increase one dimention\n\nresult=model.predict(img_pred)\nprint(result)\nif result[0][0]>result[0][1]:\n    prediction=\"Straberry_fresh\"\n    \nelse:\n    prediction=\"Straberry_scroch\"\n    \nprint(prediction)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:39:56.743111Z","iopub.execute_input":"2023-10-30T05:39:56.743376Z","iopub.status.idle":"2023-10-30T05:39:56.902239Z","shell.execute_reply.started":"2023-10-30T05:39:56.743353Z","shell.execute_reply":"2023-10-30T05:39:56.901359Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 99ms/step\n[[0. 1.]]\nStraberry_scroch\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Conclusion\nLeaf disease detection is vital for agriculture, protecting crops from diseases that harm yield and quality. Advanced methods like visual inspection, remote sensing, machine learning, and molecular techniques help identify diseases early. These technologies enable proactive measures, ensuring sustainable and productive farming while minimizing environmental impact.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#240b36;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px; color:white;\"> We appreciate your interest in this notebook. Thanks </p>\n</div>","metadata":{}}]}